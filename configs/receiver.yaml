# Configuration for receiver prediction task

# Model configuration
model:
  input_dim: 16  # Node feature dimension: x, y, vx, vy, height, weight, dx_to_kicker, dy_to_kicker, dist_to_kicker, angle_to_kicker, dx_to_goal, dy_to_goal, dist_to_goal, angle_to_goal, ball, team
  hidden_dim: 128
  num_classes: 22  # Number of players
  num_layers: 3
  num_heads: 4
  dropout: 0.2

# Optimizer configuration
optimizer:
  type: "adam"
  lr: 0.0003
  weight_decay: 0.0001

# Scheduler configuration
scheduler:
  type: "cosine"
  T_max: 50
  eta_min: 0.000001
  warmup_epochs: 5  # Warmup epochs for stability

# Training configuration
train:
  batch_size: 16  # Reduced for memory efficiency (was 32)
  epochs: 50  # ~18秒/エポック × 50 = ~15分（余裕を持たせて50エポック）
  amp: true  # Automatic mixed precision

# Data configuration
data:
  train_path: "data/processed_ck/receiver_train/data.pickle"
  val_path: "data/processed_ck/receiver_val/data.pickle"
  test_path: "data/processed_ck/receiver_test/data.pickle"
  format: "pickle"

# Loss configuration
loss:
  # Cross-entropy loss with label smoothing
  # L = -Σ y_i * log(p_i) where p_i = softmax(logits_i)
  # With label smoothing: y_i = (1 - α) * y_i + α / num_classes
  type: "cross_entropy"
  label_smoothing: 0.1  # Introduce mild label smoothing for stability
  weight: 1.0  # Loss weight
  
  # Focal loss parameters (alternative to cross-entropy)
  focal_loss:
    enabled: false
    alpha: 1.0  # Weighting factor for rare class
    gamma: 2.0  # Focusing parameter
    
  # Class weights for imbalanced datasets
  class_weights: null  # [w_0, w_1, ..., w_{num_classes-1}]
  
  # Regularization terms
  regularization:
    l2_weight: 0.0001  # L2 regularization weight
    dropout_rate: 0.2  # Dropout rate

# D2 equivariance configuration
d2:
  group_pool: false  # Disable group pooling; ReceiverModel handles D2 internally
  transforms:
    hflip: true
    vflip: true

# Early stopping configuration
early_stopping:
  patience: 10
  min_delta: 0.01  # 判定を緩める：0.01以上の改善が必要（1%以上改善がないとカウント）

# Evaluation configuration
eval:
  batch_size: 5
  min_cands_eval: 1

# System configuration
device: "auto"  # auto, cpu, cuda, mps
seed: 42
num_workers: 4  # Reduced for memory efficiency (was 12)
prefetch_factor: 2  # Reduced for memory efficiency (was 4)
persistent_workers: true  # Keep workers alive between epochs (reduces overhead)
log_level: "INFO"
log_dir: "runs"
checkpoint_dir: "checkpoints"
